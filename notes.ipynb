{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = jobs_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cache = set()\n",
    "chunks = list(log_progress(list_chunk_sizes(), every=1))\n",
    "for chunk in chunks:\n",
    "    for record in log_progress(load_chunk(chunk.name), every=10000, size=chunk.size):\n",
    "        cache.add(record.selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selections= [_ for _ in generate_selections() if _ not in cache]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, start in enumerate(xrange(0, 31695, 3000)):\n",
    "    print \"%job dump_catalog_records(log_progress(fetch_selections(log_progress(selections[{start}:{stop}], every=1)), every=10), '{index}')\".format(\n",
    "        start=start,\n",
    "        stop=start+3000,\n",
    "        index=index+29\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = sum(_.size for _ in chunks)\n",
    "records = load_chunks(_.name for _ in chunks)\n",
    "stream = map_names(log_progress(records, every=10000, size=size))\n",
    "write_table(stream, NAMES_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_table(NAMES_TABLE, by=NAME_COLUMN, chunks=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = get_table_size(NAMES_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream = read_table(NAMES_TABLE)\n",
    "groups = group_stream(log_progress(stream, every=100000, size=size), by=NAME_COLUMN)\n",
    "stream = reduce_names(groups)\n",
    "write_table(stream, UNIQUE_NAMES_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_rn_table(UNIQUE_NAMES_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = get_table_size(UNIQUE_NAMES_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = load_unique_names(UNIQUE_NAMES_TABLE)\n",
    "records = (_ for _ in log_progress(records, every=10000, size=size) if parse_name(_.name) and _.count > 1)\n",
    "stream = serialize_unique_names(records)\n",
    "write_table(stream, FILTERED_UNIQUE_NAMES_TABLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
